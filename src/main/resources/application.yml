spring:
  datasource:
    driverClassName: org.h2.Driver
    password: ''
    username: sa
    url: jdbc:h2:mem:testdb
  jpa:
    properties:
      hibernate:
        use_sql_comments: 'true'
        format_sql: 'true'
        type: info
    hibernate:
      ddl-auto: update
    show-sql: 'false'
    database-platform: org.hibernate.dialect.H2Dialect
  resources:
    chain:
      cache: 'false'
  security:
    oauth2:
      client:
        registration:
          example:
            client-id: ${OAUTH2_CLIENT_ID:client-id}
            client-secret: ${OAUTH2_CLIENT_SECRET:client-secret}
            authorization-grant-type: client_credentials
            scope: ${OAUTH2_SCOPE:openid}
        provider:
          example:
            token-uri: ${OAUTH2_TOKEN_URI:http://localhost:8080/oauth2/token}

logging:
  level:
    dev:
      langchain4j: DEBUG
      ai4j:
        openai4j:
          RequestLoggingInterceptor: DEBUG
          ResponseLoggingInterceptor: DEBUG
    root: INFO
    net:
      savantly: INFO
      savantly.app.config: DEBUG
    org.springframework.security.messaging: DEBUG
    org.springframework.web.socket.server: DEBUG
app:
  security:
    enabled: 'false'
    preauth:
      enabled: 'false'
      user-id-header-name: x-forwarded-user
      username-header-name: x-forwarded-preferred-username
      groups-header-name: x-forwarded-groups
      email-header-name: x-forwarded-email

chat:
  session:
    config:
      max-doc-results: 5
      min-doc-score: 0.5
      prompts:
        rephrase-enabled: 'true'
        rephrase-question: |
          ---
          {{messages}}
          ---
          
          Given the previous messages, rephrase the following question as a new question with more specificity. 
          Question: {{question}}
        answer-question: |
          The AI is a domain expert. It can answer questions about a wide range of topics, in a short and concise manner using Markdown formatting. 
          It uses the context from its positronic brain to answer questions. 
          If the answer to the question cannot be found in the context, the AI will let you know, but it will write a short generalized answer. 
          
          Context: {{context}}

          Given this question:
          {{question}}

          Answer:

documents:
  chunking:
    enabled: true

openai:
  chat-model-id: gpt-3.5-turbo
#  chat-model-id: gpt-4-1106-preview

server:
  error:
    includeMessage: on-param

pinecone:
  enabled: ${PINECONE_ENABLED:false}
  api-key: ${PINECONE_API_KEY}
  index: ${PINECONE_INDEX}
  environment: ${PINECONE_ENVIRONMENT}
  project-name: ${PINECONE_PROJECT_NAME}

seed:
  enabled: false

authorizaton:
  addDocsExpression: hasRole('admin')